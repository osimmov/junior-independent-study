% Here is an example of how to create a bibliography entry for an article using
% BibTeX. Generally you won't have to write these out yourself, because they are
% provided by most web sites that allow you to export citations. The string
% "clrsAlgorithms" is a citation key, and if you were citing the source in a
% document you would use \cite{clrsAlgorithms}.

@inproceedings{10.1145/3706598.3713649,
  author    = {Xu, Xiaotong (Tone) and Konnova, Arina and Gao, Bianca and Peng, Cindy and Vo, Dave and Dow, Steven P.},
  title     = {Productive vs. Reflective: How Different Ways of Integrating {AI} into Design Workflows Affect Cognition and Motivation},
  year      = {2025},
  isbn      = {9798400713941},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3706598.3713649},
  doi       = {10.1145/3706598.3713649},
  abstract  = {An increasing number of tools now integrate AI support, extending the ability of users—especially novices—to produce creative work. While AI could play various roles within such tools, less is known about how the positioning of AI affects an individual’s cognitive processes and sense of agency. To examine this relationship, we built a collaborative whiteboard plugin that integrates an LLM into design templates to facilitate reflective brainstorming activities. We conducted a between-subjects experiment with N=47 participants assigned to one of three versions of AI-support—No-AI, AI input provided incrementally (Co-led) and AI provided all at once (AI-led)—to compare the allocation of cognitive resources. Results show that the positioning of AI scaffolds shifts the underlying cognition: AI-led participants devoted more time to comprehension and synthesis, which yielded more topically diverse problems and solutions. No-AI and Co-led participants spent more time revising content and reported higher confidence in their process.},
  booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  articleno = {24},
  numpages  = {15},
  keywords  = {Creativity, Critical Thinking, Self-reflection, Learning, Brainstorming, Human-AI Collaboration, Agency, Co-piloting, Steerable AI, LLMs},
  location  = {
               },
  series    = {CHI '25},
  annote    = {This paper discusses integrating AI into workflows to improve productivity and provides guidance on how much AI usage is optimal to gain benefits. It is well cited. The authors conducted an experiment with 47 participants, dividing them into three groups and assigning them creative problem-solving tasks. One group used no AI, another worked in a co-led setting with AI, and the third relied primarily on AI. The results showed that participants who used AI generated more ideas and demonstrated higher levels of creativity when solving the problems. They also spent more time reading and synthesizing information.
               
               In this study, the authors aim to understand how different approaches to integrating AI into a creative workflow affect an individual’s ability to reflect and iterate. Their central research question is how the positioning of AI within a creative workflow influences creative outcomes.
               
               Overall, the paper demonstrates that the use of AI can enhance creativity during problem solving. It is directly relevant to my project idea: a productivity-focused platform where users write reflections and receive AI-generated suggestions to improve productivity and efficiency.
               }
}

  @inproceedings{10.1145/3699761,
  author    = {Nepal S, Pillai A, Campbell W, Massachi T, Heinz MV, Kunwar A, Choi ES, Xu X, Kuc J, Huckins JF, Holden J, Preum SM, Depp C, Jacobson N, Czerwinski MP, Granholm E, Campbell AT},
  title     = {MindScape Study: Integrating {LLM} and Behavioral Sensing for Personalized {AI}-Driven Journaling Experiences. Proc ACM Interact Mob Wearable Ubiquitous Technol.},
  year      = {2024},
  url       = {https://pmc.ncbi.nlm.nih.gov/articles/PMC11634059/?utm_source=chatgpt.com},
  abstract  = {Mental health concerns are prevalent among college students, highlighting the need for effective interventions that promote self-awareness and holistic well-being. MindScape explores a novel approach to AI-powered journaling by integrating passively collected behavioral patterns such as conversational engagement, sleep, and location with Large Language Models (LLMs). This integration creates a highly personalized and context-aware journaling experience, enhancing self-awareness and well-being by embedding behavioral intelligence into AI. We present an 8-week exploratory study with 20 college students, demonstrating the MindScape app’s efficacy in enhancing positive affect (7%), reducing negative affect (11%), loneliness (6%), and anxiety and depression, with a significant week-over-week decrease in PHQ-4 scores (−0.25 coefficient). The study highlights the advantages of contextual AI journaling, with participants particularly appreciating the tailored prompts and insights provided by the MindScape app. Our analysis also includes a comparison of responses to AI-driven contextual versus generic prompts, participant feedback insights, and proposed strategies for leveraging contextual AI journaling to improve well-being on college campuses. By showcasing the potential of contextual AI journaling to support mental health, we provide a foundation for further investigation into the effects of contextual AI journaling on mental health and well-being.},
  booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  annote    = {This article examines the emerging use of large language models in mental health support systems, focusing on both their potential benefits and inherent risks. The authors analyze how LLMs can assist with journaling, self-reflection, emotional regulation, and psychoeducation by responding empathetically to user-generated text. At the same time, the paper critically addresses concerns such as hallucinated advice, lack of clinical grounding, privacy risks, and emotional dependency.
               
               The source is highly credible, drawing on interdisciplinary research from psychology, AI ethics, and computational linguistics. It is peer-reviewed and extensively cited, situating its argument within current debates about responsible AI deployment. Rather than promoting LLMs uncritically, the authors offer a balanced evaluation and propose design guidelines for safe and effective use, including transparency, user agency, and clear system boundaries.
               
               This paper is strongly connected to my research interests in AI agents for reflective productivity and emotional insight. The paper helps frame my project within responsible AI practices and reinforces the importance of positioning AI as a tool for reflection and pattern recognition, not as a substitute for human judgment or professional help.}
}


@inproceedings{10.1145/3714394.3756347,
  author    = {Yang, HaeJi and Park, Jin Gyeong and Lee, JinKwon and Oh, Hayoung},
  title     = {POCKET-MIND: Personalized {LLM}-based Journaling to Support Emotional Awareness and Goal Pursuit},
  year      = {2026},
  isbn      = {9798400714771},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3714394.3756347},
  doi       = {10.1145/3714394.3756347},
  abstract  = {Journaling is widely recognized for promoting stress reduction, emotional resilience, and goal setting. With the rise of Large Language Models (LLMs), digital journaling systems are now capable of providing adaptive and personalized support. However, many existing solutions fail to consider users' evolving emotional states and motivational goals.We present POCKET-MIND, an LLM-based journaling application powered by GPT-4. The system utilizes a dual-prompt design to facilitate both emotional exploration and goal-oriented reflection. In a one-week pilot study with 15 participants (ages 19–34), over 80\% reported improvements in emotional awareness and goal progress. Notably, users showed increased journaling consistency and meaningful progress from the third day onward.Our findings suggest that LLM-based journaling systems can offer effective, personalized mental health support. This work contributes to the growing field of digital mental health by demonstrating the role of conversational AI in promoting psychological well-being and user engagement.},
  booktitle = {Companion of the 2025 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
  pages     = {1652–1657},
  numpages  = {6},
  keywords  = {large language models, digital journaling, mental health, goal reflection, emotion-aware interaction, human-ai collaboration},
  location  = {Finland},
  series    = {UbiComp Companion '25},
  annote    = {This paper presents PocketMind, an AI-driven mental health support system designed to provide personalized emotional assistance through natural language interaction. The authors describe the system’s architecture, which combines large language models with user journaling inputs to deliver reflective feedback, emotional validation, and coping suggestions. The primary goal of the study is to explore whether conversational AI can support mental well-being at scale while remaining accessible and non-judgmental.
               
               The source is credible and relevant. It is published in a peer-reviewed venue and written by researchers with backgrounds in human-computer interaction and mental health technologies. The methodology includes system design, user interaction scenarios, and an evaluation of ethical considerations such as overreliance on AI and emotional safety. While the paper does not claim that AI replaces professional therapy, it responsibly positions the system as a supplementary reflective tool.
               PocketMind demonstrates how structured reflection paired with AI feedback can help users articulate emotions, recognize patterns, and feel supported. Its emphasis on personalization and ethical boundaries is especially useful for designing an AI agent that gives suggestions without becoming intrusive or prescriptive. The paper supports the feasibility of using AI as a reflective companion rather than an authority.}
}


// Proposal-------------------------------------
@inproceedings{10.1145/3706598.3713295,
  author    = {Reicherts, Leon and Zhang, Zelun Tony and von Oswald, Elisabeth and Liu, Yuanting and Rogers, Yvonne and Hassib, Mariam},
  title     = {AI, Help Me Think—but for Myself: Assisting People in Complex Decision-Making by Providing Different Kinds of Cognitive Support},
  year      = {2025},
  isbn      = {9798400713941},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3706598.3713295},
  doi       = {10.1145/3706598.3713295},
  abstract  = {How can we design AI tools that effectively support human decision-making by complementing and enhancing users’ reasoning processes? Common recommendation-centric approaches face challenges such as inappropriate reliance or a lack of integration with users’ decision-making processes. Here, we explore an alternative interaction model in which the AI outputs build upon users’ own decision-making rationales. We compare this approach, which we call ExtendAI, with a recommendation-based AI. Participants in our mixed-methods user study interacted with both AIs as part of an investment decision-making task. We found that the AIs had different impacts, with ExtendAI integrating better into the decision-making process and people’s own thinking and leading to slightly better outcomes. RecommendAI was able to provide more novel insights while requiring less cognitive effort. We discuss the implications of these and other findings along with three tensions of AI-assisted decision-making which our study revealed.},
  booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  articleno = {255},
  numpages  = {19},
  keywords  = {generative AI, human-AI interaction, AI-assisted decision-making, human-AI decision-making, investment decision-making},
  location  = {
               },
  series    = {CHI '25}
}

@inproceedings{10.1145/3640543.3645198,
  author    = {Qian, Crystal and Wexler, James},
  title     = {Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration},
  year      = {2024},
  isbn      = {9798400705083},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3640543.3645198},
  doi       = {10.1145/3640543.3645198},
  abstract  = {Although recent developments in generative AI have greatly enhanced the capabilities of conversational agents such as Google’s Bard or OpenAI’s ChatGPT, it’s unclear whether the usage of these agents aids users across various contexts. To better understand how access to conversational AI affects productivity and trust, we conducted a mixed-methods, task-based user study, observing 76 software engineers (N=76) as they completed a programming exam with and without access to Bard. Effects on performance, efficiency, satisfaction, and trust vary depending on user expertise, question type (open-ended "solve" questions vs. definitive "search" questions), and measurement type (demonstrated vs. self-reported). Our findings include evidence of automation complacency, increased reliance on the AI over the course of the task, and increased performance for novices on “solve”-type questions when using the AI. We discuss common behaviors, design recommendations, and impact considerations to improve collaborations with conversational AI.},
  booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages     = {370–384},
  numpages  = {15},
  location  = {Greenville, SC, USA},
  series    = {IUI '24}
}

@inproceedings{10.1145/3643562.3672611,
  author    = {Heyman, Jennifer L and Rick, Steven R and Giacomelli, Gianni and Wen, Haoran and Laubacher, Robert and Taubenslag, Nancy and Knicker, Max and Jeddi, Younes and Ragupathy, Pranav and Curhan, Jared and Malone, Thomas},
  title     = {Supermind Ideator: How Scaffolding Human-AI Collaboration Can Increase Creativity},
  year      = {2024},
  isbn      = {9798400705540},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3643562.3672611},
  doi       = {10.1145/3643562.3672611},
  abstract  = {Previous efforts to support creative problem-solving have included (a) techniques such as brainstorming and design thinking to stimulate creative ideas, and (b) software tools to record and share these ideas. Now, generative AI technologies can suggest new ideas that might never have occurred to the users, and users can then select from these ideas or use them to stimulate even more ideas. To explore these possibilities, we developed a system called Supermind Ideator that uses a large language model (LLM) and adds prompts, fine tuning, and a specialized user interface in order to help users reformulate their problem statements and generate possible solutions. This provides scaffolding to guide users through a set of creative problem-solving techniques, including some techniques specifically intended to help generate innovative ideas about designing groups of people and/or computers (“superminds”). In an experimental study, we found that people using Supermind Ideator generated significantly more innovative ideas than those generated by people using ChatGPT or people working alone. Thus our results suggest that the benefits of using LLMs for creative problem-solving can be substantially enhanced by scaffolding designed specifically for this purpose.},
  booktitle = {Proceedings of the ACM Collective Intelligence Conference},
  pages     = {18–28},
  numpages  = {11},
  keywords  = {Collective Intelligence, Creativity, Generative AI, Innovation, Large Language Models, Scaffolding},
  location  = {Boston, MA, USA},
  series    = {CI '24}
}